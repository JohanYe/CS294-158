{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed more computational power so moved to colab at least temporarily\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt   \n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import seaborn as sns \n",
    "import os\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "n_epochs = 5\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "train_log = []\n",
    "val_log = {}\n",
    "k = 0\n",
    "best_nll = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "pickle_file = 'C:/Users/Johan/Downloads/mnist-hw1.pkl'\n",
    "#path = '/content/drive/My Drive/mnist-hw1.pkl'\n",
    "mnist = pickle.load(open(pickle_file,'rb'))\n",
    "\n",
    "X_train = mnist['train'][:20000].astype('float32')\n",
    "train_loader = torch.utils.data.DataLoader(torch.from_numpy(X_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "X_val = mnist['test'][:2000].astype('float32')\n",
    "val_loader = torch.utils.data.DataLoader(torch.from_numpy(X_val), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4,4,figsize=(5,5))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax[i,j].imshow(X_val[4*i+j]/3)\n",
    "        ax[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2d(nn.Conv2d):\n",
    "    \"\"\" Masked Conv2d spatial mask only.\"\"\"\n",
    "    \n",
    "    #args and kwargs take undefined input args\n",
    "    def __init__(self,mask_type='A', *args, **kwargs):\n",
    "        super(MaskedConv2d,self).__init__(*args, **kwargs)\n",
    "        \n",
    "        assert mask_type in {'A', 'B'}\n",
    "        \n",
    "        mask = torch.ones_like(self.weight)\n",
    "        _, _, height, width = self.weight.shape\n",
    "        \n",
    "        #Spatial masking\n",
    "        mask[:, :, height // 2, width // 2 + (mask_type == 'B'):] = 0 \n",
    "        mask[:, :, height // 2 + 1:] = 0\n",
    "        self.register_buffer('mask',mask)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.weight.data = self.weight.data.mul(self.mask) #inplace operation is faster\n",
    "        return super(MaskedConv2d, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"According to PixelCNN paper article 1 figure 5 and table 1\n",
    "    https://arxiv.org/pdf/1601.06759.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,in_channels):\n",
    "        super(ResNetBlock,self).__init__()\n",
    "\n",
    "        self.h = in_channels//2\n",
    "        self.out = nn.Sequential(\n",
    "            nn.ReLU(), #Relu first, strange setup\n",
    "            nn.Conv2d(in_channels,self.h,kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            # padding to conserve shape.\n",
    "            MaskedConv2d(in_channels=self.h,out_channels=self.h,kernel_size=3,padding=1,mask_type='B'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.h,in_channels,kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.out(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "\n",
    "    def __init__(self,n_layers=12, n_filters=128,n_classes=4,final_channels=3):\n",
    "        # 4 channels due to two bits per dim.\n",
    "        super(PixelCNN,self).__init__()\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.final_channels = final_channels\n",
    "        \n",
    "        #padding=3 so it can start in [0,0], otherwise it has to start inside the image.\n",
    "        layers = [MaskedConv2d(in_channels=3,out_channels=n_filters,kernel_size=7,padding=3,mask_type='A')]\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            layers.append(ResNetBlock(n_filters))\n",
    "\n",
    "        # PixelCNN paper uses 1024 for colored data\n",
    "        layers += [nn.ReLU()] + \\\n",
    "                [MaskedConv2d(in_channels=n_filters,out_channels=1024,kernel_size=1,mask_type='B')] +\\\n",
    "                [nn.ReLU()] +\\\n",
    "                [MaskedConv2d(in_channels=1024,out_channels=final_channels*n_classes,kernel_size=1,mask_type='B')]\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        logits = x.view([x.shape[0], self.n_classes, self.final_channels, x.shape[2], x.shape[3]])\n",
    "        out = F.softmax(logits, dim=1)  # [N, n_classes, C, H, W]\n",
    "        return logits, out\n",
    "\n",
    "    def _sample(self, n_samples=1):\n",
    "        samples = torch.Tensor(np.random.choice(4, size=(n_samples, 28, 28, 3)))\n",
    "\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                out = self(samples)\n",
    "                intensity = torch.distributions.Categorical(out).sample()\n",
    "                samples[:, i, j, :] = intensity[:, i, j, :]\n",
    "\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PixelCNN().to(device)\n",
    "optimizer = optim.Adam(net.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(logits, batch):\n",
    "    # Divide by 2 for NLL per bit\n",
    "    #print(logits.shape,batch.shape)\n",
    "    loss = F.cross_entropy(logits, batch.long(), reduction='sum') / batch_size \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n",
      "torch.Size([128, 4, 3, 28, 28]) torch.Size([128, 3, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-f6d691e58068>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mtrain_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for mini_batch in train_loader:\n",
    "        # https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/\n",
    "        mini_batch = mini_batch.permute(0,3,1,2).to(device) #To save memory we send one batch to cuda at the time\n",
    "        logits,dist = net(mini_batch)\n",
    "        loss = calc_loss(logits,mini_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_log.append(loss.item())\n",
    "        k += 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits,dist = net(X_val.permute(0,3,1,2).to(device))\n",
    "        loss = calc_loss(logits,mini_batch)\n",
    "        val_log[k] = loss.item()\n",
    "\n",
    "    if loss.item() < best_nll:\n",
    "        best_nll = loss.item()\n",
    "        save_checkpoint({'epoch': epoch,\n",
    "                         'state_dict': net.state_dict()}, save_dir)\n",
    "\n",
    "    print('[Epoch %d/%d][Step: %d] Train Loss: %s Test Loss: %s' \\\n",
    "          % (epoch, n_epochs, k, np.mean(train_log[-10:]), val_log[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch.clone().long().view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
